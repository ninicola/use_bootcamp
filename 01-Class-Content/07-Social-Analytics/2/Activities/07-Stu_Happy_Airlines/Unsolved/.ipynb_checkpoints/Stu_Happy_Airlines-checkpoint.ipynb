{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent Twitter Miles\n",
    "\n",
    "Airlines get a lot of flack on twitter, especially from big time Journalists who think they are the only ones affected by flying. Lets see what kind of tone everyone else takes when tweeting about them.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Your goal is to retrieve 1000 tweets for each of the 7 popular airlines and run a VADER sentiment analysis on them.\n",
    "\n",
    "* Create an empty list to hold to results from each airline,\n",
    "\n",
    "* Filter the tweets using the given \"Real Person\" filter variables.\n",
    "\n",
    "* Create a \"sentiment\" dictionary for each airline that includes the search term, and the averages of the compound, neutral, positive, and negative scores.  Print this dictionary and append it to a list holding each airline's results.\n",
    "\n",
    "* Create a DataFrame to display the results.\n",
    "\n",
    "### HINTS\n",
    "\n",
    "* Start with a subset of data for each airline while testing. Then, adapt your code to collect all 1000 tweets per airline.\n",
    "\n",
    "* For a reference on using max_id, see this link: [Working with Timelines](https://developer.twitter.com/en/docs/tweets/timelines/guides/working-with-timelines)\n",
    "\n",
    "- - -\n",
    "\n",
    "### Copyright\n",
    "\n",
    "Trilogy Education Services Â© 2017. All Rights Reserved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Twitter API Keys\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target Search Term\n",
    "target_terms = (\"@SouthwestAir\", \"@AmericanAir\", \"@SpiritAirlines\",\n",
    "                \"@Virginatlantic\", \"@Delta\", \"@AlaskaAir\", \"@KLM\")\n",
    "\n",
    "# \"Real Person\" Filters\n",
    "min_tweets = 5\n",
    "max_tweets = 10000\n",
    "max_followers = 2500\n",
    "max_following = 2500\n",
    "lang = \"en\"\n",
    "\n",
    "# List to hold sentiment\n",
    "results_list = []\n",
    "\n",
    "# Loop through all target users\n",
    "for target in target_terms:\n",
    "\n",
    "    # Variable for holding the oldest tweet\n",
    "    oldest_tweet = None\n",
    "\n",
    "    # Variables for holding sentiments\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "\n",
    "    # Loop through 10 times\n",
    "    for x in range(10):\n",
    "\n",
    "        # Run search around each tweet\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets[\"statuses\"]:\n",
    "\n",
    "            # Use filters to check if user meets conditions\n",
    "            # YOUR CODE HERE\n",
    "\n",
    "                # Run Vader Analysis on each tweet\n",
    "                # YOUR CODE HERE\n",
    "\n",
    "                # Add each value to the appropriate list\n",
    "                # YOUR CODE HERE\n",
    "                \n",
    "            # Set the new oldest_tweet value\n",
    "            oldest_tweet = tweet[\"id\"] - 1\n",
    "\n",
    "    # Create a dictionary of the Average Sentiments\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # Print the Sentiments\n",
    "    print(sentiment)\n",
    "    print()\n",
    "    \n",
    "    # Append the dictionary to results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame using results_list and display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
